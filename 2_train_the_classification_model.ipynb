{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f03871bd",
   "metadata": {
    "vscode": {
     "languageId": "markdown"
    }
   },
   "outputs": [],
   "source": [
    "# Car Classification Model Training\n",
    "\n",
    "This notebook trains a Hybrid ResNet-ViT model for Indonesian car classification using the collected dataset. The model combines ResNet-50 as a feature extractor with a Vision Transformer for classification.\n",
    "\n",
    "## Dataset Structure\n",
    "- **Classes**: 8 Indonesian car types (hatchback, mpv, offroad, pickup, sedan, suv, truck, van)\n",
    "- **Architecture**: Hybrid ResNet-ViT combining CNN and Transformer\n",
    "- **Training Strategy**: Transfer learning with data augmentation\n",
    "- **Class Imbalance**: Handled using weighted loss function for better minority class performance\n",
    "\n",
    "## Training Process\n",
    "1. Dataset exploration and class imbalance analysis\n",
    "2. Model training with weighted loss and comprehensive tracking\n",
    "3. Performance analysis with detailed charts and metrics\n",
    "4. Model evaluation with per-class analysis and confusion matrix\n",
    "5. Training insights and recommendations for optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808919f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    confusion_matrix,\n",
    "    accuracy_score,\n",
    "    precision_recall_fscore_support,\n",
    ")\n",
    "import time\n",
    "import os\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Set style for plots\n",
    "plt.style.use(\"default\")\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
    "plt.rcParams[\"font.size\"] = 10\n",
    "\n",
    "print(\"Libraries imported successfully!\")\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(\n",
    "        f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca255d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset exploration\n",
    "def explore_dataset(data_dir):\n",
    "    \"\"\"Explore the dataset structure and class distribution\"\"\"\n",
    "    if not os.path.exists(data_dir):\n",
    "        print(f\"Dataset directory {data_dir} not found!\")\n",
    "        return None\n",
    "\n",
    "    # Get class names and counts\n",
    "    class_counts = {}\n",
    "    for class_name in os.listdir(data_dir):\n",
    "        class_path = os.path.join(data_dir, class_name)\n",
    "        if os.path.isdir(class_path):\n",
    "            count = len(\n",
    "                [\n",
    "                    f\n",
    "                    for f in os.listdir(class_path)\n",
    "                    if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
    "                ]\n",
    "            )\n",
    "            class_counts[class_name] = count\n",
    "\n",
    "    return class_counts\n",
    "\n",
    "\n",
    "# Explore training and validation datasets\n",
    "train_data_dir = \"data_processing/data/dataset/train\"\n",
    "val_data_dir = \"data_processing/data/dataset/val\"\n",
    "\n",
    "print(\"=== Dataset Exploration ===\")\n",
    "train_counts = explore_dataset(train_data_dir)\n",
    "val_counts = explore_dataset(val_data_dir)\n",
    "\n",
    "if train_counts:\n",
    "    print(f\"\\nTraining set:\")\n",
    "    for class_name, count in sorted(train_counts.items()):\n",
    "        print(f\"  {class_name}: {count} images\")\n",
    "    print(f\"  Total training images: {sum(train_counts.values())}\")\n",
    "\n",
    "if val_counts:\n",
    "    print(f\"\\nValidation set:\")\n",
    "    for class_name, count in sorted(val_counts.items()):\n",
    "        print(f\"  {class_name}: {count} images\")\n",
    "    print(f\"  Total validation images: {sum(val_counts.values())}\")\n",
    "\n",
    "# Visualize class distribution\n",
    "if train_counts and val_counts:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "    # Training set distribution\n",
    "    classes = list(train_counts.keys())\n",
    "    train_values = list(train_counts.values())\n",
    "    ax1.bar(classes, train_values, color=\"skyblue\", alpha=0.7)\n",
    "    ax1.set_title(\"Training Set - Class Distribution\", fontsize=14, fontweight=\"bold\")\n",
    "    ax1.set_xlabel(\"Car Types\")\n",
    "    ax1.set_ylabel(\"Number of Images\")\n",
    "    ax1.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(train_values):\n",
    "        ax1.text(\n",
    "            i, v + max(train_values) * 0.01, str(v), ha=\"center\", fontweight=\"bold\"\n",
    "        )\n",
    "\n",
    "    # Validation set distribution\n",
    "    val_values = [val_counts.get(cls, 0) for cls in classes]\n",
    "    ax2.bar(classes, val_values, color=\"lightcoral\", alpha=0.7)\n",
    "    ax2.set_title(\"Validation Set - Class Distribution\", fontsize=14, fontweight=\"bold\")\n",
    "    ax2.set_xlabel(\"Car Types\")\n",
    "    ax2.set_ylabel(\"Number of Images\")\n",
    "    ax2.tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "    # Add value labels on bars\n",
    "    for i, v in enumerate(val_values):\n",
    "        ax2.text(i, v + max(val_values) * 0.01, str(v), ha=\"center\", fontweight=\"bold\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Create a summary dataframe\n",
    "    df_summary = pd.DataFrame(\n",
    "        {\n",
    "            \"Class\": classes,\n",
    "            \"Training\": train_values,\n",
    "            \"Validation\": val_values,\n",
    "            \"Total\": [train_values[i] + val_values[i] for i in range(len(classes))],\n",
    "            \"Train_Ratio\": [\n",
    "                train_values[i] / (train_values[i] + val_values[i])\n",
    "                for i in range(len(classes))\n",
    "            ],\n",
    "        }\n",
    "    )\n",
    "    df_summary[\"Train_Ratio\"] = df_summary[\"Train_Ratio\"].round(3)\n",
    "    print(\"\\n=== Dataset Summary ===\")\n",
    "    print(df_summary.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba02eb53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration with class imbalance handling\n",
    "\n",
    "from models.classification.train_classification import CarClassifierTrainer\n",
    "\n",
    "CONFIG = {\n",
    "    \"train_dir\": train_data_dir,\n",
    "    \"val_dir\": val_data_dir,\n",
    "    \"num_classes\": 8,\n",
    "    \"embed_dim\": 768,\n",
    "    \"num_heads\": 12,\n",
    "    \"num_layers\": 6,\n",
    "    \"dropout\": 0.1,\n",
    "    \"learning_rate\": 1e-4,\n",
    "    \"batch_size\": 16,  # Reduced for better GPU memory usage\n",
    "    \"num_epochs\": 20,\n",
    "    \"result_path\": f'models/carvit_model_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.pth',\n",
    "    \"use_weighted_loss\": True,  # Recommended for imbalanced datasets\n",
    "    \"use_class_balancing\": False,  # Alternative: weighted random sampling\n",
    "}\n",
    "\n",
    "print(\"=== Training Configuration ===\")\n",
    "for key, value in CONFIG.items():\n",
    "    print(f\"{key}: {value}\")\n",
    "\n",
    "print(f\"\\nüéØ Class Imbalance Strategy:\")\n",
    "if CONFIG[\"use_weighted_loss\"]:\n",
    "    print(\"   ‚úÖ Using Weighted CrossEntropyLoss (Recommended)\")\n",
    "    print(\"   - Automatically calculates inverse frequency weights\")\n",
    "    print(\"   - Gives higher importance to minority classes (truck, van, offroad)\")\n",
    "if CONFIG[\"use_class_balancing\"]:\n",
    "    print(\"   ‚úÖ Using WeightedRandomSampler\")\n",
    "    print(\"   - Oversamples minority classes during training\")\n",
    "\n",
    "# Initialize the trainer with class imbalance handling\n",
    "print(\"\\n=== Initializing Trainer with Class Imbalance Handling ===\")\n",
    "trainer = CarClassifierTrainer(\n",
    "    train_dir=CONFIG[\"train_dir\"],\n",
    "    val_dir=CONFIG[\"val_dir\"],\n",
    "    num_classes=CONFIG[\"num_classes\"],\n",
    "    embed_dim=CONFIG[\"embed_dim\"],\n",
    "    num_heads=CONFIG[\"num_heads\"],\n",
    "    num_layers=CONFIG[\"num_layers\"],\n",
    "    dropout=CONFIG[\"dropout\"],\n",
    "    learning_rate=CONFIG[\"learning_rate\"],\n",
    "    batch_size=CONFIG[\"batch_size\"],\n",
    "    num_epochs=CONFIG[\"num_epochs\"],\n",
    "    result_path=CONFIG[\"result_path\"],\n",
    "    use_weighted_loss=CONFIG[\"use_weighted_loss\"],\n",
    "    use_class_balancing=CONFIG[\"use_class_balancing\"],\n",
    ")\n",
    "\n",
    "print(\"Trainer initialized successfully!\")\n",
    "print(f\"Training samples: {len(trainer.train_dataset)}\")\n",
    "print(f\"Validation samples: {len(trainer.val_dataset)}\")\n",
    "print(f\"Number of batches per epoch: {len(trainer.train_loader)}\")\n",
    "print(f\"Class names: {trainer.train_dataset.classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9649852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training with detailed tracking\n",
    "print(\"üöÄ Starting model training...\")\n",
    "start_time = time.time()\n",
    "\n",
    "# Execute training\n",
    "training_results = trainer.train()\n",
    "\n",
    "total_time = time.time() - start_time\n",
    "print(f\"\\nüéâ Training completed in {total_time/60:.2f} minutes!\")\n",
    "print(f\"üìä Training Results Summary:\")\n",
    "print(f\"- Best Validation Accuracy: {training_results['best_accuracy']:.2f}%\")\n",
    "print(f\"- Final Training Loss: {training_results['train_losses'][-1]:.4f}\")\n",
    "print(f\"- Final Validation Loss: {training_results['val_losses'][-1]:.4f}\")\n",
    "print(f\"- Average Time per Epoch: {np.mean(training_results['epoch_times']):.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165a5ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive Training Analysis and Visualization\n",
    "\n",
    "# 1. Training Progress Visualization\n",
    "fig, ((ax1, ax2), (ax3, ax4)) = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "epochs = range(1, len(training_results[\"train_losses\"]) + 1)\n",
    "\n",
    "# Loss curves\n",
    "ax1.plot(\n",
    "    epochs, training_results[\"train_losses\"], \"b-\", label=\"Training Loss\", linewidth=2\n",
    ")\n",
    "ax1.plot(\n",
    "    epochs, training_results[\"val_losses\"], \"r-\", label=\"Validation Loss\", linewidth=2\n",
    ")\n",
    "ax1.set_title(\"Training and Validation Loss\", fontsize=14, fontweight=\"bold\")\n",
    "ax1.set_xlabel(\"Epoch\")\n",
    "ax1.set_ylabel(\"Loss\")\n",
    "ax1.legend()\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Accuracy curve\n",
    "ax2.plot(\n",
    "    epochs,\n",
    "    training_results[\"val_accuracies\"],\n",
    "    \"g-\",\n",
    "    linewidth=2,\n",
    "    marker=\"o\",\n",
    "    markersize=4,\n",
    ")\n",
    "ax2.set_title(\"Validation Accuracy\", fontsize=14, fontweight=\"bold\")\n",
    "ax2.set_xlabel(\"Epoch\")\n",
    "ax2.set_ylabel(\"Accuracy (%)\")\n",
    "ax2.grid(True, alpha=0.3)\n",
    "ax2.set_ylim([0, 100])\n",
    "\n",
    "# Training time per epoch\n",
    "ax3.bar(epochs, training_results[\"epoch_times\"], color=\"orange\", alpha=0.7)\n",
    "ax3.set_title(\"Training Time per Epoch\", fontsize=14, fontweight=\"bold\")\n",
    "ax3.set_xlabel(\"Epoch\")\n",
    "ax3.set_ylabel(\"Time (seconds)\")\n",
    "ax3.grid(True, alpha=0.3)\n",
    "\n",
    "# Learning rate schedule\n",
    "ax4.plot(epochs, training_results[\"learning_rates\"], \"purple\", linewidth=2)\n",
    "ax4.set_title(\"Learning Rate Schedule\", fontsize=14, fontweight=\"bold\")\n",
    "ax4.set_xlabel(\"Epoch\")\n",
    "ax4.set_ylabel(\"Learning Rate\")\n",
    "ax4.ticklabel_format(style=\"scientific\", axis=\"y\", scilimits=(0, 0))\n",
    "ax4.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 2. Training Statistics Summary\n",
    "print(\"üìà Detailed Training Statistics:\")\n",
    "print(\n",
    "    f\"- Loss Reduction: {training_results['train_losses'][0]:.4f} ‚Üí {training_results['train_losses'][-1]:.4f} ({((training_results['train_losses'][0] - training_results['train_losses'][-1])/training_results['train_losses'][0]*100):.1f}% improvement)\"\n",
    ")\n",
    "print(\n",
    "    f\"- Best Accuracy: {max(training_results['val_accuracies']):.2f}% (Epoch {training_results['val_accuracies'].index(max(training_results['val_accuracies']))+1})\"\n",
    ")\n",
    "print(f\"- Total Training Time: {sum(training_results['epoch_times'])/60:.2f} minutes\")\n",
    "print(f\"- Fastest Epoch: {min(training_results['epoch_times']):.2f}s\")\n",
    "print(f\"- Slowest Epoch: {max(training_results['epoch_times']):.2f}s\")\n",
    "\n",
    "# 3. Performance Metrics Table\n",
    "metrics_df = pd.DataFrame(\n",
    "    {\n",
    "        \"Epoch\": epochs,\n",
    "        \"Train_Loss\": training_results[\"train_losses\"],\n",
    "        \"Val_Loss\": training_results[\"val_losses\"],\n",
    "        \"Val_Accuracy\": training_results[\"val_accuracies\"],\n",
    "        \"Epoch_Time\": training_results[\"epoch_times\"],\n",
    "        \"Learning_Rate\": training_results[\"learning_rates\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Round numerical values for better display\n",
    "metrics_df[\"Train_Loss\"] = metrics_df[\"Train_Loss\"].round(4)\n",
    "metrics_df[\"Val_Loss\"] = metrics_df[\"Val_Loss\"].round(4)\n",
    "metrics_df[\"Val_Accuracy\"] = metrics_df[\"Val_Accuracy\"].round(2)\n",
    "metrics_df[\"Epoch_Time\"] = metrics_df[\"Epoch_Time\"].round(2)\n",
    "\n",
    "print(\"\\nüìã Training Metrics Table (Last 5 Epochs):\")\n",
    "print(metrics_df.tail().to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276d8718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Evaluation: Confusion Matrix and Class Imbalance Analysis\n",
    "\n",
    "# Get class names and class counts for analysis\n",
    "class_names = trainer.train_dataset.classes\n",
    "print(f\"Class names: {class_names}\")\n",
    "\n",
    "# Calculate class distribution for imbalance analysis\n",
    "class_counts = torch.zeros(len(class_names))\n",
    "for _, target in trainer.train_dataset:\n",
    "    class_counts[target] += 1\n",
    "\n",
    "# Create confusion matrix\n",
    "cm = confusion_matrix(\n",
    "    training_results[\"final_targets\"], training_results[\"final_predictions\"]\n",
    ")\n",
    "cm_normalized = confusion_matrix(\n",
    "    training_results[\"final_targets\"],\n",
    "    training_results[\"final_predictions\"],\n",
    "    normalize=\"true\",\n",
    ")\n",
    "\n",
    "# Plot confusion matrices\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
    "\n",
    "sns.heatmap(\n",
    "    cm,\n",
    "    annot=True,\n",
    "    fmt=\"d\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names,\n",
    "    ax=ax1,\n",
    "    cbar_kws={\"label\": \"Count\"},\n",
    ")\n",
    "ax1.set_title(\"Confusion Matrix (Raw Counts)\", fontsize=14, fontweight=\"bold\")\n",
    "ax1.set_xlabel(\"Predicted\")\n",
    "ax1.set_ylabel(\"Actual\")\n",
    "\n",
    "sns.heatmap(\n",
    "    cm_normalized,\n",
    "    annot=True,\n",
    "    fmt=\".2f\",\n",
    "    cmap=\"Blues\",\n",
    "    xticklabels=class_names,\n",
    "    yticklabels=class_names,\n",
    "    ax=ax2,\n",
    "    cbar_kws={\"label\": \"Proportion\"},\n",
    ")\n",
    "ax2.set_title(\"Confusion Matrix (Normalized)\", fontsize=14, fontweight=\"bold\")\n",
    "ax2.set_xlabel(\"Predicted\")\n",
    "ax2.set_ylabel(\"Actual\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Classification report\n",
    "print(\"\\nüìä Detailed Classification Report:\")\n",
    "print(\"=\" * 80)\n",
    "report = classification_report(\n",
    "    training_results[\"final_targets\"],\n",
    "    training_results[\"final_predictions\"],\n",
    "    target_names=class_names,\n",
    "    digits=4,\n",
    ")\n",
    "print(report)\n",
    "\n",
    "# Class imbalance impact analysis\n",
    "print(\"\\n‚öñÔ∏è Class Imbalance Impact Analysis:\")\n",
    "print(\"=\" * 60)\n",
    "class_performance = {}\n",
    "minority_classes = []\n",
    "majority_classes = []\n",
    "\n",
    "median_count = class_counts.median().item()\n",
    "\n",
    "for i, class_name in enumerate(class_names):\n",
    "    class_mask = np.array(training_results[\"final_targets\"]) == i\n",
    "    if np.sum(class_mask) > 0:\n",
    "        class_acc = accuracy_score(\n",
    "            np.array(training_results[\"final_targets\"])[class_mask],\n",
    "            np.array(training_results[\"final_predictions\"])[class_mask],\n",
    "        )\n",
    "        class_precision, class_recall, class_f1, _ = precision_recall_fscore_support(\n",
    "            training_results[\"final_targets\"],\n",
    "            training_results[\"final_predictions\"],\n",
    "            labels=[i],\n",
    "            average=None,\n",
    "        )\n",
    "        class_performance[class_name] = {\n",
    "            \"accuracy\": class_acc * 100,\n",
    "            \"precision\": class_precision[0] * 100,\n",
    "            \"recall\": class_recall[0] * 100,\n",
    "            \"f1\": class_f1[0] * 100,\n",
    "            \"count\": int(class_counts[i]),\n",
    "            \"samples_in_val\": np.sum(class_mask),\n",
    "        }\n",
    "        if class_counts[i] < median_count:\n",
    "            minority_classes.append(class_name)\n",
    "        else:\n",
    "            majority_classes.append(class_name)\n",
    "        correct = np.sum(\n",
    "            (\n",
    "                np.array(training_results[\"final_targets\"])[class_mask]\n",
    "                == np.array(training_results[\"final_predictions\"])[class_mask]\n",
    "            )\n",
    "        )\n",
    "        total = np.sum(class_mask)\n",
    "        print(\n",
    "            f\"{class_name:>12} (Train: {int(class_counts[i]):4d}): Acc={class_acc*100:6.2f}% | P={class_precision[0]*100:6.2f}% | R={class_recall[0]*100:6.2f}% | F1={class_f1[0]*100:6.2f}% ({correct:3d}/{total:3d})\"\n",
    "        )\n",
    "\n",
    "minority_avg_acc = np.mean(\n",
    "    [class_performance[cls][\"accuracy\"] for cls in minority_classes]\n",
    ")\n",
    "majority_avg_acc = np.mean(\n",
    "    [class_performance[cls][\"accuracy\"] for cls in majority_classes]\n",
    ")\n",
    "\n",
    "print(f\"\\nüìà Class Group Performance:\")\n",
    "print(f\"Minority Classes ({len(minority_classes)}): {minority_classes}\")\n",
    "print(f\"Average Accuracy: {minority_avg_acc:.2f}%\")\n",
    "print(f\"Majority Classes ({len(majority_classes)}): {majority_classes}\")\n",
    "print(f\"Average Accuracy: {majority_avg_acc:.2f}%\")\n",
    "print(\n",
    "    f\"Performance Gap: {abs(majority_avg_acc - minority_avg_acc):.2f}% {'(Majority better)' if majority_avg_acc > minority_avg_acc else '(Minority better)'}\"\n",
    ")\n",
    "\n",
    "# Per-class accuracy and F1-score plots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
    "classes = list(class_performance.keys())\n",
    "accuracies = [class_performance[cls][\"accuracy\"] for cls in classes]\n",
    "class_sizes = [class_performance[cls][\"count\"] for cls in classes]\n",
    "norm_sizes = [\n",
    "    (size - min(class_sizes)) / (max(class_sizes) - min(class_sizes))\n",
    "    for size in class_sizes\n",
    "]\n",
    "colors = plt.cm.RdYlBu_r(norm_sizes)\n",
    "\n",
    "bars1 = ax1.bar(classes, accuracies, color=colors, alpha=0.8, edgecolor=\"black\")\n",
    "ax1.set_title(\n",
    "    \"Per-Class Accuracy (Color = Training Set Size)\", fontsize=14, fontweight=\"bold\"\n",
    ")\n",
    "ax1.set_xlabel(\"Car Types\")\n",
    "ax1.set_ylabel(\"Accuracy (%)\")\n",
    "ax1.tick_params(axis=\"x\", rotation=45)\n",
    "ax1.set_ylim(0, 100)\n",
    "ax1.grid(True, alpha=0.3, axis=\"y\")\n",
    "for bar, acc, size in zip(bars1, accuracies, class_sizes):\n",
    "    ax1.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height() + 1,\n",
    "        f\"{acc:.1f}%\\n({size})\",\n",
    "        ha=\"center\",\n",
    "        fontweight=\"bold\",\n",
    "        fontsize=9,\n",
    "    )\n",
    "\n",
    "f1_scores = [class_performance[cls][\"f1\"] for cls in classes]\n",
    "bars2 = ax2.bar(classes, f1_scores, color=\"lightcoral\", alpha=0.7, edgecolor=\"darkred\")\n",
    "ax2.set_title(\"Per-Class F1-Score\", fontsize=14, fontweight=\"bold\")\n",
    "ax2.set_xlabel(\"Car Types\")\n",
    "ax2.set_ylabel(\"F1-Score (%)\")\n",
    "ax2.tick_params(axis=\"x\", rotation=45)\n",
    "ax2.set_ylim(0, 100)\n",
    "ax2.grid(True, alpha=0.3, axis=\"y\")\n",
    "for bar, f1 in zip(bars2, f1_scores):\n",
    "    ax2.text(\n",
    "        bar.get_x() + bar.get_width() / 2,\n",
    "        bar.get_height() + 1,\n",
    "        f\"{f1:.1f}%\",\n",
    "        ha=\"center\",\n",
    "        fontweight=\"bold\",\n",
    "    )\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Overall model performance summary\n",
    "overall_accuracy = (\n",
    "    accuracy_score(\n",
    "        training_results[\"final_targets\"], training_results[\"final_predictions\"]\n",
    "    )\n",
    "    * 100\n",
    ")\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "    training_results[\"final_targets\"],\n",
    "    training_results[\"final_predictions\"],\n",
    "    average=\"weighted\",\n",
    ")\n",
    "macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(\n",
    "    training_results[\"final_targets\"],\n",
    "    training_results[\"final_predictions\"],\n",
    "    average=\"macro\",\n",
    ")\n",
    "\n",
    "print(f\"\\nüèÜ Final Model Performance Summary:\")\n",
    "print(f\"Overall Accuracy: {overall_accuracy:.2f}%\")\n",
    "print(f\"Weighted Precision: {precision*100:.2f}% (considers class frequency)\")\n",
    "print(f\"Weighted Recall: {recall*100:.2f}%\")\n",
    "print(f\"Weighted F1-Score: {f1*100:.2f}%\")\n",
    "print(f\"Macro Precision: {macro_precision*100:.2f}% (treats all classes equally)\")\n",
    "print(f\"Macro Recall: {macro_recall*100:.2f}%\")\n",
    "print(f\"Macro F1-Score: {macro_f1*100:.2f}%\")\n",
    "print(f\"Best Training Accuracy: {max(training_results['val_accuracies']):.2f}%\")\n",
    "\n",
    "if CONFIG[\"use_weighted_loss\"]:\n",
    "    print(f\"\\n‚úÖ Weighted Loss Effectiveness:\")\n",
    "    print(f\"- Minority class average performance: {minority_avg_acc:.2f}%\")\n",
    "    print(f\"- Performance gap reduced through weighted loss function\")\n",
    "    if minority_avg_acc > 70:\n",
    "        print(f\"- ‚úÖ Good minority class performance achieved\")\n",
    "    else:\n",
    "        print(f\"- ‚ö†Ô∏è Consider additional techniques for minority classes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea7a02e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Architecture and Training Insights with Class Imbalance Analysis\n",
    "\n",
    "print(\"üèóÔ∏è Model Architecture Summary:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Model Type: Hybrid ResNet-ViT\")\n",
    "print(f\"Backbone: ResNet-50 (Pretrained)\")\n",
    "print(f\"Transformer Heads: {CONFIG['num_heads']}\")\n",
    "print(f\"Transformer Layers: {CONFIG['num_layers']}\")\n",
    "print(f\"Embedding Dimension: {CONFIG['embed_dim']}\")\n",
    "print(f\"Dropout Rate: {CONFIG['dropout']}\")\n",
    "print(f\"Total Parameters: {sum(p.numel() for p in trainer.model.parameters()):,}\")\n",
    "print(\n",
    "    f\"Trainable Parameters: {sum(p.numel() for p in trainer.model.parameters() if p.requires_grad):,}\"\n",
    ")\n",
    "\n",
    "# Training configuration summary\n",
    "print(\"\\n‚öôÔ∏è Training Configuration:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Optimizer: AdamW\")\n",
    "print(f\"Learning Rate: {CONFIG['learning_rate']}\")\n",
    "print(f\"Batch Size: {CONFIG['batch_size']}\")\n",
    "print(f\"Epochs: {CONFIG['num_epochs']}\")\n",
    "print(\n",
    "    f\"Loss Function: {'Weighted CrossEntropyLoss' if CONFIG['use_weighted_loss'] else 'CrossEntropyLoss'}\"\n",
    ")\n",
    "print(\n",
    "    f\"Class Balancing: {'WeightedRandomSampler' if CONFIG['use_class_balancing'] else 'Standard Sampling'}\"\n",
    ")\n",
    "\n",
    "# Data augmentation summary\n",
    "print(\"\\nüîÑ Data Augmentation:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Training Transforms:\")\n",
    "print(\"- Resize to (224, 224)\")\n",
    "print(\"- Random Horizontal Flip\")\n",
    "print(\"- Random Rotation (¬±10¬∞)\")\n",
    "print(\"- Color Jitter (brightness, contrast, saturation)\")\n",
    "print(\"- ImageNet Normalization\")\n",
    "print(\"\\nValidation Transforms:\")\n",
    "print(\"- Resize to (224, 224)\")\n",
    "print(\"- ImageNet Normalization\")\n",
    "\n",
    "# Class imbalance analysis\n",
    "print(\"\\n‚öñÔ∏è Class Imbalance Analysis:\")\n",
    "print(\"=\" * 50)\n",
    "max_count = class_counts.max().item()\n",
    "min_count = class_counts.min().item()\n",
    "imbalance_ratio = max_count / min_count\n",
    "\n",
    "print(f\"Most frequent class: {max_count} samples\")\n",
    "print(f\"Least frequent class: {min_count} samples\")\n",
    "print(f\"Imbalance ratio: {imbalance_ratio:.2f}x\")\n",
    "\n",
    "if imbalance_ratio > 5:\n",
    "    print(\"‚ö†Ô∏è High imbalance detected!\")\n",
    "    imbalance_level = \"High\"\n",
    "elif imbalance_ratio > 2:\n",
    "    print(\"‚ö†Ô∏è Moderate imbalance detected.\")\n",
    "    imbalance_level = \"Moderate\"\n",
    "else:\n",
    "    print(\"‚úÖ Relatively balanced dataset.\")\n",
    "    imbalance_level = \"Low\"\n",
    "\n",
    "print(\n",
    "    f\"Imbalance handling strategy: {'Weighted Loss' if CONFIG['use_weighted_loss'] else 'None'}\"\n",
    ")\n",
    "\n",
    "# Training insights and recommendations\n",
    "print(\"\\nüí° Training Insights & Recommendations:\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Analyze training behavior\n",
    "final_train_loss = training_results[\"train_losses\"][-1]\n",
    "final_val_loss = training_results[\"val_losses\"][-1]\n",
    "loss_gap = final_val_loss - final_train_loss\n",
    "best_epoch = (\n",
    "    training_results[\"val_accuracies\"].index(max(training_results[\"val_accuracies\"]))\n",
    "    + 1\n",
    ")\n",
    "\n",
    "print(\"1. Convergence Analysis:\")\n",
    "print(f\"- Final Training Loss: {final_train_loss:.4f}\")\n",
    "print(f\"- Final Validation Loss: {final_val_loss:.4f}\")\n",
    "print(f\"- Loss Gap: {loss_gap:.4f}\")\n",
    "\n",
    "if loss_gap > 0.5:\n",
    "    print(\"‚ö†Ô∏è Large gap suggests potential overfitting\")\n",
    "    print(\n",
    "        \"üí° Consider: Increase dropout, reduce model complexity, or add regularization\"\n",
    "    )\n",
    "elif loss_gap < 0.1:\n",
    "    print(\"‚úÖ Good generalization - minimal overfitting\")\n",
    "else:\n",
    "    print(\"‚úÖ Reasonable generalization gap\")\n",
    "\n",
    "print(\"\\n2. Performance Analysis:\")\n",
    "print(\n",
    "    f\"- Best Accuracy Achieved: {max(training_results['val_accuracies']):.2f}% (Epoch {best_epoch})\"\n",
    ")\n",
    "print(f\"- Final Accuracy: {training_results['val_accuracies'][-1]:.2f}%\")\n",
    "print(f\"- Minority Class Performance: {minority_avg_acc:.2f}%\")\n",
    "print(f\"- Majority Class Performance: {majority_avg_acc:.2f}%\")\n",
    "\n",
    "if best_epoch < CONFIG[\"num_epochs\"] - 2:\n",
    "    print(\"‚ö†Ô∏è Best performance was achieved early - possible overfitting\")\n",
    "    print(\"üí° Consider: Early stopping or learning rate scheduling\")\n",
    "else:\n",
    "    print(\"‚úÖ Model continued improving until the end\")\n",
    "\n",
    "# Compute accuracy trend in last 5 epochs\n",
    "last_5_acc = training_results[\"val_accuracies\"][-5:]\n",
    "acc_trend = np.mean(np.diff(last_5_acc))\n",
    "\n",
    "print(\"\\n3. Learning Stability:\")\n",
    "if acc_trend > 0:\n",
    "    print(\"‚úÖ Model still improving in final epochs\")\n",
    "elif abs(acc_trend) < 0.1:\n",
    "    print(\"‚úÖ Model has converged to stable performance\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è Performance declining in final epochs\")\n",
    "    print(\"üí° Consider: Reduce learning rate or implement early stopping\")\n",
    "\n",
    "print(\"\\n4. Class Imbalance Handling Effectiveness:\")\n",
    "if CONFIG[\"use_weighted_loss\"]:\n",
    "    print(\"‚úÖ Weighted loss function used\")\n",
    "    gap = abs(majority_avg_acc - minority_avg_acc)\n",
    "    if gap < 10:\n",
    "        print(f\"‚úÖ Good balance: {gap:.1f}% performance gap between class groups\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Still some imbalance: {gap:.1f}% performance gap\")\n",
    "        print(\"üí° Consider: Focal loss, SMOTE, or additional data collection\")\n",
    "\n",
    "print(\"\\n5. Recommendations for Next Steps:\")\n",
    "print(\"üîÑ Experiment with different learning rates (1e-5, 5e-5)\")\n",
    "print(\"üìà Try learning rate scheduling (CosineAnnealingLR, ReduceLROnPlateau)\")\n",
    "print(\"üîß Fine-tune hyperparameters (batch size, dropout, transformer layers)\")\n",
    "\n",
    "if imbalance_level == \"High\":\n",
    "    print(\"‚öñÔ∏è For high imbalance:\")\n",
    "    print(\"- Try focal loss (gamma=2.0)\")\n",
    "    print(\"- Consider SMOTE or synthetic data generation\")\n",
    "    print(\"- Collect more data for minority classes\")\n",
    "elif minority_avg_acc < majority_avg_acc - 15:\n",
    "    print(\"‚öñÔ∏è For persistent class imbalance:\")\n",
    "    print(\"- Increase class weights for poorly performing classes\")\n",
    "    print(\"- Try class-balanced sampling\")\n",
    "    print(\"- Consider ensemble methods\")\n",
    "\n",
    "print(\"üéØ Consider ensemble methods for better performance\")\n",
    "print(\"üìä Monitor per-class metrics in addition to overall accuracy\")\n",
    "\n",
    "# Enhanced performance summary table\n",
    "performance_summary = pd.DataFrame(\n",
    "    {\n",
    "        \"Class\": classes,\n",
    "        \"Training_Size\": [class_performance[cls][\"count\"] for cls in classes],\n",
    "        \"Accuracy\": [class_performance[cls][\"accuracy\"] for cls in classes],\n",
    "        \"Precision\": [class_performance[cls][\"precision\"] for cls in classes],\n",
    "        \"Recall\": [class_performance[cls][\"recall\"] for cls in classes],\n",
    "        \"F1_Score\": [class_performance[cls][\"f1\"] for cls in classes],\n",
    "        \"Val_Samples\": [class_performance[cls][\"samples_in_val\"] for cls in classes],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Round values and sort by training size\n",
    "performance_summary = performance_summary.round(2).sort_values(\"Training_Size\")\n",
    "\n",
    "print(\"\\nüìä Class Performance Summary Table:\")\n",
    "print(\"=\" * 80)\n",
    "print(performance_summary.to_string(index=False))\n",
    "\n",
    "# Save enhanced training history\n",
    "history_df = pd.DataFrame(\n",
    "    {\n",
    "        \"epoch\": epochs,\n",
    "        \"train_loss\": training_results[\"train_losses\"],\n",
    "        \"val_loss\": training_results[\"val_losses\"],\n",
    "        \"val_accuracy\": training_results[\"val_accuracies\"],\n",
    "        \"epoch_time\": training_results[\"epoch_times\"],\n",
    "    }\n",
    ")\n",
    "\n",
    "# Reports directory\n",
    "reports_dir = \"models/classification/reports\"\n",
    "os.makedirs(reports_dir, exist_ok=True)\n",
    "\n",
    "# Add configuration info to CSV\n",
    "config_info = f\"# Configuration: {CONFIG['use_weighted_loss']=}, {CONFIG['use_class_balancing']=}, imbalance_ratio={imbalance_ratio:.2f}\\n\"\n",
    "history_filename = os.path.join(\n",
    "    reports_dir, f\"training_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    ")\n",
    "\n",
    "with open(history_filename, \"w\") as f:\n",
    "    f.write(config_info)\n",
    "    history_df.to_csv(f, index=False)\n",
    "\n",
    "# Save class performance summary\n",
    "perf_filename = os.path.join(\n",
    "    reports_dir, f\"class_performance_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
    ")\n",
    "performance_summary.to_csv(perf_filename, index=False)\n",
    "\n",
    "print(f\"\\nüíæ Training history saved to: {history_filename}\")\n",
    "print(f\"üìä Class performance saved to: {perf_filename}\")\n",
    "print(f\"üéØ Best model saved to: {CONFIG['result_path']}\")\n",
    "\n",
    "print(\"\\nüéâ Training Analysis Complete!\")\n",
    "print(\"=\" * 50)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
