{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/luthfiarifin/Hybrid-RViT-Car-Retrieval/blob/main/2_train_the_classification_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "519b36a0",
      "metadata": {
        "id": "519b36a0"
      },
      "source": [
        "# Car Classification Model Training\n",
        "\n",
        "This notebook trains a Hybrid ResNet-ViT model for Indonesian car classification using the collected dataset. The model combines ResNet-50 as a feature extractor with a Vision Transformer for classification.\n",
        "\n",
        "## Dataset Structure\n",
        "- **Classes**: 8 Indonesian car types (hatchback, mpv, offroad, pickup, sedan, suv, truck, van)\n",
        "- **Architecture**: Hybrid ResNet-ViT combining CNN and Transformer\n",
        "- **Training Strategy**: Transfer learning with data augmentation\n",
        "- **Class Imbalance**: Handled using weighted loss function for better minority class performance\n",
        "\n",
        "## Training Process\n",
        "1. Dataset exploration and class imbalance analysis\n",
        "2. Model training with weighted loss and comprehensive tracking\n",
        "3. Performance analysis with detailed charts and metrics\n",
        "4. Model evaluation with per-class analysis and confusion matrix\n",
        "5. Training insights and recommendations for optimization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "808919f2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "808919f2",
        "outputId": "9dc5ada8-e887-44f7-eb53-8a5d05abb6a1"
      },
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torchvision import transforms\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.metrics import (\n",
        "    classification_report,\n",
        "    confusion_matrix,\n",
        "    accuracy_score,\n",
        "    precision_recall_fscore_support,\n",
        ")\n",
        "import time\n",
        "import os\n",
        "from datetime import datetime\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "# Set style for plots\n",
        "plt.style.use(\"default\")\n",
        "sns.set_palette(\"husl\")\n",
        "plt.rcParams[\"figure.figsize\"] = (12, 8)\n",
        "plt.rcParams[\"font.size\"] = 10\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"CUDA device: {torch.cuda.get_device_name(0)}\")\n",
        "    print(\n",
        "        f\"CUDA memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\"\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ca255d19",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 873
        },
        "id": "ca255d19",
        "outputId": "93b847f9-f3bc-418b-e53a-5d44f6cb6f6b"
      },
      "outputs": [],
      "source": [
        "# Dataset exploration\n",
        "def explore_dataset(data_dir):\n",
        "    \"\"\"Explore the dataset structure and class distribution\"\"\"\n",
        "    if not os.path.exists(data_dir):\n",
        "        print(f\"Dataset directory {data_dir} not found!\")\n",
        "        return None\n",
        "\n",
        "    # Get class names and counts\n",
        "    class_counts = {}\n",
        "    for class_name in os.listdir(data_dir):\n",
        "        class_path = os.path.join(data_dir, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            count = len(\n",
        "                [\n",
        "                    f\n",
        "                    for f in os.listdir(class_path)\n",
        "                    if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))\n",
        "                ]\n",
        "            )\n",
        "            class_counts[class_name] = count\n",
        "\n",
        "    return class_counts\n",
        "\n",
        "\n",
        "# Explore training and validation datasets\n",
        "train_data_dir = \"data_processing/data/dataset/train\"\n",
        "val_data_dir = \"data_processing/data/dataset/val\"\n",
        "\n",
        "print(\"=== Dataset Exploration ===\")\n",
        "train_counts = explore_dataset(train_data_dir)\n",
        "val_counts = explore_dataset(val_data_dir)\n",
        "\n",
        "if train_counts:\n",
        "    print(f\"\\nTraining set:\")\n",
        "    for class_name, count in sorted(train_counts.items()):\n",
        "        print(f\"  {class_name}: {count} images\")\n",
        "    print(f\"  Total training images: {sum(train_counts.values())}\")\n",
        "\n",
        "if val_counts:\n",
        "    print(f\"\\nValidation set:\")\n",
        "    for class_name, count in sorted(val_counts.items()):\n",
        "        print(f\"  {class_name}: {count} images\")\n",
        "    print(f\"  Total validation images: {sum(val_counts.values())}\")\n",
        "\n",
        "# Visualize class distribution\n",
        "if train_counts and val_counts:\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))\n",
        "\n",
        "    # Training set distribution\n",
        "    classes = list(train_counts.keys())\n",
        "    train_values = list(train_counts.values())\n",
        "    ax1.bar(classes, train_values, color=\"skyblue\", alpha=0.7)\n",
        "    ax1.set_title(\"Training Set - Class Distribution\", fontsize=14, fontweight=\"bold\")\n",
        "    ax1.set_xlabel(\"Car Types\")\n",
        "    ax1.set_ylabel(\"Number of Images\")\n",
        "    ax1.tick_params(axis=\"x\", rotation=45)\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for i, v in enumerate(train_values):\n",
        "        ax1.text(\n",
        "            i, v + max(train_values) * 0.01, str(v), ha=\"center\", fontweight=\"bold\"\n",
        "        )\n",
        "\n",
        "    # Validation set distribution\n",
        "    val_values = [val_counts.get(cls, 0) for cls in classes]\n",
        "    ax2.bar(classes, val_values, color=\"lightcoral\", alpha=0.7)\n",
        "    ax2.set_title(\"Validation Set - Class Distribution\", fontsize=14, fontweight=\"bold\")\n",
        "    ax2.set_xlabel(\"Car Types\")\n",
        "    ax2.set_ylabel(\"Number of Images\")\n",
        "    ax2.tick_params(axis=\"x\", rotation=45)\n",
        "\n",
        "    # Add value labels on bars\n",
        "    for i, v in enumerate(val_values):\n",
        "        ax2.text(i, v + max(val_values) * 0.01, str(v), ha=\"center\", fontweight=\"bold\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    # Create a summary dataframe\n",
        "    df_summary = pd.DataFrame(\n",
        "        {\n",
        "            \"Class\": classes,\n",
        "            \"Training\": train_values,\n",
        "            \"Validation\": val_values,\n",
        "            \"Total\": [train_values[i] + val_values[i] for i in range(len(classes))],\n",
        "            \"Train_Ratio\": [\n",
        "                train_values[i] / (train_values[i] + val_values[i])\n",
        "                for i in range(len(classes))\n",
        "            ],\n",
        "        }\n",
        "    )\n",
        "    df_summary[\"Train_Ratio\"] = df_summary[\"Train_Ratio\"].round(3)\n",
        "    print(\"\\n=== Dataset Summary ===\")\n",
        "    print(df_summary.to_string(index=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba02eb53",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ba02eb53",
        "outputId": "f4603e29-ba47-4a45-9d4c-2c1a04e46790"
      },
      "outputs": [],
      "source": [
        "# Training configuration with class imbalance handling\n",
        "\n",
        "from models.classification.train_classification import CarClassifierTrainer\n",
        "\n",
        "CONFIG = {\n",
        "    \"train_dir\": train_data_dir,\n",
        "    \"val_dir\": val_data_dir,\n",
        "    \"num_classes\": 8,\n",
        "    \"embed_dim\": 768,\n",
        "    \"num_heads\": 12,\n",
        "    \"num_layers\": 6,\n",
        "    \"dropout\": 0.1,\n",
        "    \"learning_rate\": 1e-4,\n",
        "    \"batch_size\": 96,\n",
        "    \"num_epochs\": 25,\n",
        "    \"result_path\": f'models/results/carvit_model_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.pth',\n",
        "    \"use_weighted_loss\": True,\n",
        "    \"use_class_balancing\": False,\n",
        "    \"num_workers\": 8,\n",
        "    \"early_stopping_patience\": 7,\n",
        "    \"early_stopping_delta\": 0.001,\n",
        "    \"early_stopping_verbose\": True,\n",
        "}\n",
        "\n",
        "print(\"=== Training Configuration ===\")\n",
        "for key, value in CONFIG.items():\n",
        "    print(f\"{key}: {value}\")\n",
        "\n",
        "# Initialize the trainer with class imbalance handling and early stopping\n",
        "print(\"\\n=== Initializing Trainer with Class Imbalance Handling & Early Stopping ===\")\n",
        "trainer = CarClassifierTrainer(\n",
        "    train_dir=CONFIG[\"train_dir\"],\n",
        "    val_dir=CONFIG[\"val_dir\"],\n",
        "    num_classes=CONFIG[\"num_classes\"],\n",
        "    embed_dim=CONFIG[\"embed_dim\"],\n",
        "    num_heads=CONFIG[\"num_heads\"],\n",
        "    num_layers=CONFIG[\"num_layers\"],\n",
        "    dropout=CONFIG[\"dropout\"],\n",
        "    learning_rate=CONFIG[\"learning_rate\"],\n",
        "    batch_size=CONFIG[\"batch_size\"],\n",
        "    num_epochs=CONFIG[\"num_epochs\"],\n",
        "    result_path=CONFIG[\"result_path\"],\n",
        "    use_weighted_loss=CONFIG[\"use_weighted_loss\"],\n",
        "    use_class_balancing=CONFIG[\"use_class_balancing\"],\n",
        "    num_workers=CONFIG[\"num_workers\"],\n",
        "    early_stopping_patience=CONFIG[\"early_stopping_patience\"],\n",
        "    early_stopping_delta=CONFIG[\"early_stopping_delta\"],\n",
        "    early_stopping_verbose=CONFIG[\"early_stopping_verbose\"],\n",
        ")\n",
        "\n",
        "print(\"Trainer initialized successfully!\")\n",
        "print(f\"Training samples: {len(trainer.train_dataset)}\")\n",
        "print(f\"Validation samples: {len(trainer.val_dataset)}\")\n",
        "print(f\"Number of batches per epoch: {len(trainer.train_loader)}\")\n",
        "print(f\"Class names: {trainer.train_dataset.classes}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c9649852",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9649852",
        "outputId": "70630eb3-963a-4219-db31-56be90fff178"
      },
      "outputs": [],
      "source": [
        "# Start training with detailed tracking\n",
        "print(\"üöÄ Starting model training...\")\n",
        "start_time = time.time()\n",
        "\n",
        "# Execute training\n",
        "training_results = trainer.train()\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "print(f\"\\nüéâ Training completed in {total_time/60:.2f} minutes!\")\n",
        "print(f\"üìä Training Results Summary:\")\n",
        "print(f\"- Best Validation Accuracy: {training_results['best_accuracy']:.2f}%\")\n",
        "print(f\"- Final Training Loss: {training_results['train_losses'][-1]:.4f}\")\n",
        "print(f\"- Final Validation Loss: {training_results['val_losses'][-1]:.4f}\")\n",
        "print(f\"- Average Time per Epoch: {np.mean(training_results['epoch_times']):.2f}s\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "165a5ace",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 737
        },
        "id": "165a5ace",
        "outputId": "b5cfdd33-8bea-45c6-b695-028649046723"
      },
      "outputs": [],
      "source": [
        "# Comprehensive Training Analysis and Visualization\n",
        "\n",
        "# 1. Training Progress Visualization\n",
        "fig, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = plt.subplots(3, 2, figsize=(16, 18))\n",
        "\n",
        "epochs = range(1, len(training_results[\"train_losses\"]) + 1)\n",
        "\n",
        "# Loss curves\n",
        "ax1.plot(\n",
        "    epochs, training_results[\"train_losses\"], \"b-\", label=\"Training Loss\", linewidth=2\n",
        ")\n",
        "ax1.plot(\n",
        "    epochs, training_results[\"val_losses\"], \"r-\", label=\"Validation Loss\", linewidth=2\n",
        ")\n",
        "ax1.set_title(\"Training and Validation Loss\", fontsize=14, fontweight=\"bold\")\n",
        "ax1.set_xlabel(\"Epoch\")\n",
        "ax1.set_ylabel(\"Loss\")\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Add early stopping marker if triggered\n",
        "if training_results.get(\"early_stopping_triggered\", False):\n",
        "    stopped_epoch = training_results[\"stopped_epoch\"]\n",
        "    ax1.axvline(x=stopped_epoch, color='red', linestyle='--', linewidth=2, alpha=0.7, label=f'Early Stop (Epoch {stopped_epoch})')\n",
        "    ax1.legend()\n",
        "\n",
        "# Accuracy curve\n",
        "ax2.plot(\n",
        "    epochs,\n",
        "    training_results[\"val_accuracies\"],\n",
        "    \"g-\",\n",
        "    linewidth=2,\n",
        "    marker=\"o\",\n",
        "    markersize=4,\n",
        ")\n",
        "ax2.set_title(\"Validation Accuracy\", fontsize=14, fontweight=\"bold\")\n",
        "ax2.set_xlabel(\"Epoch\")\n",
        "ax2.set_ylabel(\"Accuracy (%)\")\n",
        "ax2.grid(True, alpha=0.3)\n",
        "ax2.set_ylim([0, 100])\n",
        "\n",
        "# Add early stopping marker for accuracy\n",
        "if training_results.get(\"early_stopping_triggered\", False):\n",
        "    ax2.axvline(x=stopped_epoch, color='red', linestyle='--', linewidth=2, alpha=0.7, label=f'Early Stop (Epoch {stopped_epoch})')\n",
        "    ax2.legend()\n",
        "\n",
        "# Training time per epoch\n",
        "ax3.bar(epochs, training_results[\"epoch_times\"], color=\"orange\", alpha=0.7)\n",
        "ax3.set_title(\"Training Time per Epoch\", fontsize=14, fontweight=\"bold\")\n",
        "ax3.set_xlabel(\"Epoch\")\n",
        "ax3.set_ylabel(\"Time (seconds)\")\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Learning rate schedule\n",
        "ax4.plot(epochs, training_results[\"learning_rates\"], \"purple\", linewidth=2)\n",
        "ax4.set_title(\"Learning Rate Schedule\", fontsize=14, fontweight=\"bold\")\n",
        "ax4.set_xlabel(\"Epoch\")\n",
        "ax4.set_ylabel(\"Learning Rate\")\n",
        "ax4.ticklabel_format(style=\"scientific\", axis=\"y\", scilimits=(0, 0))\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "# Early Stopping Counter History\n",
        "if \"early_stopping_counter_history\" in training_results:\n",
        "    counter_history = training_results[\"early_stopping_counter_history\"]\n",
        "    patience = training_results.get(\"early_stopping_patience\", 7)\n",
        "    \n",
        "    ax5.plot(epochs, counter_history, \"red\", linewidth=2, marker=\"o\", markersize=4)\n",
        "    ax5.axhline(y=patience, color='red', linestyle='--', alpha=0.7, label=f'Patience Limit ({patience})')\n",
        "    ax5.set_title(\"Early Stopping Counter\", fontsize=14, fontweight=\"bold\")\n",
        "    ax5.set_xlabel(\"Epoch\")\n",
        "    ax5.set_ylabel(\"Consecutive epochs without improvement\")\n",
        "    ax5.set_ylim([0, max(max(counter_history), patience) + 1])\n",
        "    ax5.grid(True, alpha=0.3)\n",
        "    ax5.legend()\n",
        "    \n",
        "    # Fill danger zone\n",
        "    ax5.fill_between(epochs, 0, counter_history, where=np.array(counter_history) >= patience-1, \n",
        "                     alpha=0.3, color='red', label='Danger Zone')\n",
        "\n",
        "# Model Performance Summary\n",
        "total_epochs = len(epochs)\n",
        "actual_epochs = training_results.get(\"stopped_epoch\", total_epochs)\n",
        "best_epoch = training_results[\"val_accuracies\"].index(max(training_results[\"val_accuracies\"])) + 1\n",
        "\n",
        "performance_data = [\n",
        "    training_results[\"best_accuracy\"],\n",
        "    training_results[\"val_losses\"][-1],\n",
        "    actual_epochs,\n",
        "    sum(training_results[\"epoch_times\"])/60\n",
        "]\n",
        "performance_labels = ['Best Accuracy (%)', 'Final Val Loss', 'Total Epochs', 'Total Time (min)']\n",
        "\n",
        "ax6.barh(performance_labels, performance_data, color=['green', 'orange', 'blue', 'purple'], alpha=0.7)\n",
        "ax6.set_title(\"Training Summary\", fontsize=14, fontweight=\"bold\")\n",
        "ax6.set_xlabel(\"Value\")\n",
        "\n",
        "# Add value labels on bars\n",
        "for i, v in enumerate(performance_data):\n",
        "    if i == 0:  # Accuracy\n",
        "        ax6.text(v + max(performance_data) * 0.01, i, f'{v:.2f}%', va='center', fontweight='bold')\n",
        "    elif i == 1:  # Loss\n",
        "        ax6.text(v + max(performance_data) * 0.01, i, f'{v:.4f}', va='center', fontweight='bold')\n",
        "    elif i == 2:  # Epochs\n",
        "        ax6.text(v + max(performance_data) * 0.01, i, f'{int(v)}', va='center', fontweight='bold')\n",
        "    else:  # Time\n",
        "        ax6.text(v + max(performance_data) * 0.01, i, f'{v:.1f}', va='center', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 2. Early Stopping Analysis\n",
        "print(\"üõë Early Stopping Analysis:\")\n",
        "print(\"=\" * 50)\n",
        "if training_results.get(\"early_stopping_triggered\", False):\n",
        "    stopped_epoch = training_results[\"stopped_epoch\"]\n",
        "    total_planned = CONFIG[\"num_epochs\"]\n",
        "    time_saved = sum(training_results[\"epoch_times\"]) / len(training_results[\"epoch_times\"]) * (total_planned - stopped_epoch)\n",
        "    \n",
        "    print(f\"‚úÖ Early stopping was triggered!\")\n",
        "    print(f\"üìç Stopped at epoch: {stopped_epoch}/{total_planned}\")\n",
        "    print(f\"‚è∞ Training time saved: ~{time_saved/60:.1f} minutes\")\n",
        "    print(f\"üéØ Best validation loss: {training_results['best_val_loss']:.6f}\")\n",
        "    print(f\"üìà Final validation accuracy: {training_results['val_accuracies'][-1]:.2f}%\")\n",
        "    print(f\"üèÜ Best validation accuracy: {training_results['best_accuracy']:.2f}% (Epoch {best_epoch})\")\n",
        "    \n",
        "    # Check if best accuracy was achieved before early stopping\n",
        "    if best_epoch < stopped_epoch:\n",
        "        print(f\"‚ÑπÔ∏è  Best accuracy was achieved {stopped_epoch - best_epoch} epochs before early stopping\")\n",
        "    else:\n",
        "        print(f\"‚ÑπÔ∏è  Best accuracy was achieved at the final epoch\")\n",
        "        \n",
        "    # Analyze early stopping effectiveness\n",
        "    loss_improvement = training_results[\"val_losses\"][0] - training_results[\"best_val_loss\"]\n",
        "    print(f\"üìâ Total validation loss improvement: {loss_improvement:.6f}\")\n",
        "    \n",
        "else:\n",
        "    print(f\"‚ùå Early stopping was NOT triggered\")\n",
        "    print(f\"üìç Training completed all {CONFIG['num_epochs']} epochs\")\n",
        "    print(f\"üéØ Final validation loss: {training_results['val_losses'][-1]:.6f}\")\n",
        "    print(f\"üìà Final validation accuracy: {training_results['val_accuracies'][-1]:.2f}%\")\n",
        "    print(f\"üèÜ Best validation accuracy: {training_results['best_accuracy']:.2f}% (Epoch {best_epoch})\")\n",
        "    print(f\"üí° Consider: Reducing patience or increasing epochs for better convergence\")\n",
        "\n",
        "# 3. Training Statistics Summary\n",
        "print(\"\\nüìà Detailed Training Statistics:\")\n",
        "print(\"=\" * 50)\n",
        "print(\n",
        "    f\"- Loss Reduction: {training_results['train_losses'][0]:.4f} ‚Üí {training_results['train_losses'][-1]:.4f} ({((training_results['train_losses'][0] - training_results['train_losses'][-1])/training_results['train_losses'][0]*100):.1f}% improvement)\"\n",
        ")\n",
        "print(\n",
        "    f\"- Best Accuracy: {max(training_results['val_accuracies']):.2f}% (Epoch {training_results['val_accuracies'].index(max(training_results['val_accuracies']))+1})\"\n",
        ")\n",
        "print(f\"- Total Training Time: {sum(training_results['epoch_times'])/60:.2f} minutes\")\n",
        "print(f\"- Average Time per Epoch: {np.mean(training_results['epoch_times']):.2f}s\")\n",
        "print(f\"- Fastest Epoch: {min(training_results['epoch_times']):.2f}s\")\n",
        "print(f\"- Slowest Epoch: {max(training_results['epoch_times']):.2f}s\")\n",
        "\n",
        "# Early stopping counter statistics\n",
        "if \"early_stopping_counter_history\" in training_results:\n",
        "    counter_history = training_results[\"early_stopping_counter_history\"]\n",
        "    max_counter = max(counter_history)\n",
        "    avg_counter = np.mean(counter_history)\n",
        "    print(f\"- Max Early Stop Counter: {max_counter}\")\n",
        "    print(f\"- Average Early Stop Counter: {avg_counter:.2f}\")\n",
        "    print(f\"- Times Close to Early Stop (>{CONFIG['early_stopping_patience']-2}): {sum(1 for x in counter_history if x > CONFIG['early_stopping_patience']-2)}\")\n",
        "\n",
        "# 4. Performance Metrics Table with Early Stopping Info\n",
        "metrics_df = pd.DataFrame(\n",
        "    {\n",
        "        \"Epoch\": epochs,\n",
        "        \"Train_Loss\": training_results[\"train_losses\"],\n",
        "        \"Val_Loss\": training_results[\"val_losses\"],\n",
        "        \"Val_Accuracy\": training_results[\"val_accuracies\"],\n",
        "        \"Epoch_Time\": training_results[\"epoch_times\"],\n",
        "        \"Learning_Rate\": training_results[\"learning_rates\"],\n",
        "        \"ES_Counter\": training_results.get(\"early_stopping_counter_history\", [0] * len(epochs)),\n",
        "    }\n",
        ")\n",
        "\n",
        "# Round numerical values for better display\n",
        "metrics_df[\"Train_Loss\"] = metrics_df[\"Train_Loss\"].round(4)\n",
        "metrics_df[\"Val_Loss\"] = metrics_df[\"Val_Loss\"].round(4)\n",
        "metrics_df[\"Val_Accuracy\"] = metrics_df[\"Val_Accuracy\"].round(2)\n",
        "metrics_df[\"Epoch_Time\"] = metrics_df[\"Epoch_Time\"].round(2)\n",
        "\n",
        "print(\"\\nüìã Training Metrics Table (Last 5 Epochs):\")\n",
        "print(metrics_df.tail().to_string(index=False))\n",
        "\n",
        "print(f\"\\nüîç Early Stopping Configuration:\")\n",
        "print(f\"- Patience: {CONFIG['early_stopping_patience']} epochs\")\n",
        "print(f\"- Delta: {CONFIG['early_stopping_delta']} (minimum improvement threshold)\")\n",
        "print(f\"- Verbose: {CONFIG['early_stopping_verbose']}\")\n",
        "print(f\"- Monitoring: Validation Loss (lower is better)\")\n",
        "\n",
        "# Recommendations based on early stopping behavior\n",
        "print(f\"\\nüí° Early Stopping Recommendations:\")\n",
        "if training_results.get(\"early_stopping_triggered\", False):\n",
        "    if training_results[\"stopped_epoch\"] < CONFIG[\"num_epochs\"] * 0.5:\n",
        "        print(\"‚ö†Ô∏è  Early stopping triggered very early - consider:\")\n",
        "        print(\"- Reducing learning rate\")\n",
        "        print(\"- Increasing patience\")\n",
        "        print(\"- Adding learning rate scheduling\")\n",
        "    else:\n",
        "        print(\"‚úÖ Early stopping worked well - good balance of training time and performance\")\n",
        "        print(\"- Consider similar patience for future experiments\")\n",
        "else:\n",
        "    final_counter = counter_history[-1] if \"early_stopping_counter_history\" in training_results else 0\n",
        "    if final_counter > CONFIG[\"early_stopping_patience\"] * 0.7:\n",
        "        print(\"‚ö†Ô∏è  Close to early stopping at the end - consider:\")\n",
        "        print(\"- Increasing total epochs\")\n",
        "        print(\"- Implementing learning rate decay\")\n",
        "    else:\n",
        "        print(\"‚ÑπÔ∏è  Model was still improving - consider:\")\n",
        "        print(\"- Increasing total epochs\")\n",
        "        print(\"- Reducing patience if training time is a concern\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "276d8718",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "276d8718",
        "outputId": "68e05400-b2a6-4b91-beaa-bb493e4b5e98"
      },
      "outputs": [],
      "source": [
        "# Model Evaluation: Confusion Matrix and Class Imbalance Analysis\n",
        "\n",
        "# Get class names and class counts for analysis\n",
        "class_names = trainer.train_dataset.classes\n",
        "print(f\"Class names: {class_names}\")\n",
        "\n",
        "# Calculate class distribution for imbalance analysis\n",
        "class_counts = torch.zeros(len(class_names))\n",
        "for _, target in trainer.train_dataset:\n",
        "    class_counts[target] += 1\n",
        "\n",
        "# Create confusion matrix\n",
        "cm = confusion_matrix(\n",
        "    training_results[\"final_targets\"], training_results[\"final_predictions\"]\n",
        ")\n",
        "cm_normalized = confusion_matrix(\n",
        "    training_results[\"final_targets\"],\n",
        "    training_results[\"final_predictions\"],\n",
        "    normalize=\"true\",\n",
        ")\n",
        "\n",
        "# Plot confusion matrices\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
        "\n",
        "sns.heatmap(\n",
        "    cm,\n",
        "    annot=True,\n",
        "    fmt=\"d\",\n",
        "    cmap=\"Blues\",\n",
        "    xticklabels=class_names,\n",
        "    yticklabels=class_names,\n",
        "    ax=ax1,\n",
        "    cbar_kws={\"label\": \"Count\"},\n",
        ")\n",
        "ax1.set_title(\"Confusion Matrix (Raw Counts)\", fontsize=14, fontweight=\"bold\")\n",
        "ax1.set_xlabel(\"Predicted\")\n",
        "ax1.set_ylabel(\"Actual\")\n",
        "\n",
        "sns.heatmap(\n",
        "    cm_normalized,\n",
        "    annot=True,\n",
        "    fmt=\".2f\",\n",
        "    cmap=\"Blues\",\n",
        "    xticklabels=class_names,\n",
        "    yticklabels=class_names,\n",
        "    ax=ax2,\n",
        "    cbar_kws={\"label\": \"Proportion\"},\n",
        ")\n",
        "ax2.set_title(\"Confusion Matrix (Normalized)\", fontsize=14, fontweight=\"bold\")\n",
        "ax2.set_xlabel(\"Predicted\")\n",
        "ax2.set_ylabel(\"Actual\")\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nüìä Detailed Classification Report:\")\n",
        "print(\"=\" * 80)\n",
        "report = classification_report(\n",
        "    training_results[\"final_targets\"],\n",
        "    training_results[\"final_predictions\"],\n",
        "    target_names=class_names,\n",
        "    digits=4,\n",
        ")\n",
        "print(report)\n",
        "\n",
        "# Class imbalance impact analysis\n",
        "print(\"\\n‚öñÔ∏è Class Imbalance Impact Analysis:\")\n",
        "print(\"=\" * 60)\n",
        "class_performance = {}\n",
        "minority_classes = []\n",
        "majority_classes = []\n",
        "\n",
        "median_count = class_counts.median().item()\n",
        "\n",
        "for i, class_name in enumerate(class_names):\n",
        "    class_mask = np.array(training_results[\"final_targets\"]) == i\n",
        "    if np.sum(class_mask) > 0:\n",
        "        class_acc = accuracy_score(\n",
        "            np.array(training_results[\"final_targets\"])[class_mask],\n",
        "            np.array(training_results[\"final_predictions\"])[class_mask],\n",
        "        )\n",
        "        class_precision, class_recall, class_f1, _ = precision_recall_fscore_support(\n",
        "            training_results[\"final_targets\"],\n",
        "            training_results[\"final_predictions\"],\n",
        "            labels=[i],\n",
        "            average=None,\n",
        "        )\n",
        "        class_performance[class_name] = {\n",
        "            \"accuracy\": class_acc * 100,\n",
        "            \"precision\": class_precision[0] * 100,\n",
        "            \"recall\": class_recall[0] * 100,\n",
        "            \"f1\": class_f1[0] * 100,\n",
        "            \"count\": int(class_counts[i]),\n",
        "            \"samples_in_val\": np.sum(class_mask),\n",
        "        }\n",
        "        if class_counts[i] < median_count:\n",
        "            minority_classes.append(class_name)\n",
        "        else:\n",
        "            majority_classes.append(class_name)\n",
        "        correct = np.sum(\n",
        "            (\n",
        "                np.array(training_results[\"final_targets\"])[class_mask]\n",
        "                == np.array(training_results[\"final_predictions\"])[class_mask]\n",
        "            )\n",
        "        )\n",
        "        total = np.sum(class_mask)\n",
        "        print(\n",
        "            f\"{class_name:>12} (Train: {int(class_counts[i]):4d}): Acc={class_acc*100:6.2f}% | P={class_precision[0]*100:6.2f}% | R={class_recall[0]*100:6.2f}% | F1={class_f1[0]*100:6.2f}% ({correct:3d}/{total:3d})\"\n",
        "        )\n",
        "\n",
        "minority_avg_acc = np.mean(\n",
        "    [class_performance[cls][\"accuracy\"] for cls in minority_classes]\n",
        ")\n",
        "majority_avg_acc = np.mean(\n",
        "    [class_performance[cls][\"accuracy\"] for cls in majority_classes]\n",
        ")\n",
        "\n",
        "print(f\"\\nüìà Class Group Performance:\")\n",
        "print(f\"Minority Classes ({len(minority_classes)}): {minority_classes}\")\n",
        "print(f\"Average Accuracy: {minority_avg_acc:.2f}%\")\n",
        "print(f\"Majority Classes ({len(majority_classes)}): {majority_classes}\")\n",
        "print(f\"Average Accuracy: {majority_avg_acc:.2f}%\")\n",
        "print(\n",
        "    f\"Performance Gap: {abs(majority_avg_acc - minority_avg_acc):.2f}% {'(Majority better)' if majority_avg_acc > minority_avg_acc else '(Minority better)'}\"\n",
        ")\n",
        "\n",
        "# Per-class accuracy and F1-score plots\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 7))\n",
        "classes = list(class_performance.keys())\n",
        "accuracies = [class_performance[cls][\"accuracy\"] for cls in classes]\n",
        "class_sizes = [class_performance[cls][\"count\"] for cls in classes]\n",
        "norm_sizes = [\n",
        "    (size - min(class_sizes)) / (max(class_sizes) - min(class_sizes))\n",
        "    for size in class_sizes\n",
        "]\n",
        "colors = plt.cm.RdYlBu_r(norm_sizes)\n",
        "\n",
        "bars1 = ax1.bar(classes, accuracies, color=colors, alpha=0.8, edgecolor=\"black\")\n",
        "ax1.set_title(\n",
        "    \"Per-Class Accuracy (Color = Training Set Size)\", fontsize=14, fontweight=\"bold\"\n",
        ")\n",
        "ax1.set_xlabel(\"Car Types\")\n",
        "ax1.set_ylabel(\"Accuracy (%)\")\n",
        "ax1.tick_params(axis=\"x\", rotation=45)\n",
        "ax1.set_ylim(0, 100)\n",
        "ax1.grid(True, alpha=0.3, axis=\"y\")\n",
        "for bar, acc, size in zip(bars1, accuracies, class_sizes):\n",
        "    ax1.text(\n",
        "        bar.get_x() + bar.get_width() / 2,\n",
        "        bar.get_height() + 1,\n",
        "        f\"{acc:.1f}%\\n({size})\",\n",
        "        ha=\"center\",\n",
        "        fontweight=\"bold\",\n",
        "        fontsize=9,\n",
        "    )\n",
        "\n",
        "f1_scores = [class_performance[cls][\"f1\"] for cls in classes]\n",
        "bars2 = ax2.bar(classes, f1_scores, color=\"lightcoral\", alpha=0.7, edgecolor=\"darkred\")\n",
        "ax2.set_title(\"Per-Class F1-Score\", fontsize=14, fontweight=\"bold\")\n",
        "ax2.set_xlabel(\"Car Types\")\n",
        "ax2.set_ylabel(\"F1-Score (%)\")\n",
        "ax2.tick_params(axis=\"x\", rotation=45)\n",
        "ax2.set_ylim(0, 100)\n",
        "ax2.grid(True, alpha=0.3, axis=\"y\")\n",
        "for bar, f1 in zip(bars2, f1_scores):\n",
        "    ax2.text(\n",
        "        bar.get_x() + bar.get_width() / 2,\n",
        "        bar.get_height() + 1,\n",
        "        f\"{f1:.1f}%\",\n",
        "        ha=\"center\",\n",
        "        fontweight=\"bold\",\n",
        "    )\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Overall model performance summary\n",
        "overall_accuracy = (\n",
        "    accuracy_score(\n",
        "        training_results[\"final_targets\"], training_results[\"final_predictions\"]\n",
        "    )\n",
        "    * 100\n",
        ")\n",
        "precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "    training_results[\"final_targets\"],\n",
        "    training_results[\"final_predictions\"],\n",
        "    average=\"weighted\",\n",
        ")\n",
        "macro_precision, macro_recall, macro_f1, _ = precision_recall_fscore_support(\n",
        "    training_results[\"final_targets\"],\n",
        "    training_results[\"final_predictions\"],\n",
        "    average=\"macro\",\n",
        ")\n",
        "\n",
        "print(f\"\\nüèÜ Final Model Performance Summary:\")\n",
        "print(f\"Overall Accuracy: {overall_accuracy:.2f}%\")\n",
        "print(f\"Weighted Precision: {precision*100:.2f}% (considers class frequency)\")\n",
        "print(f\"Weighted Recall: {recall*100:.2f}%\")\n",
        "print(f\"Weighted F1-Score: {f1*100:.2f}%\")\n",
        "print(f\"Macro Precision: {macro_precision*100:.2f}% (treats all classes equally)\")\n",
        "print(f\"Macro Recall: {macro_recall*100:.2f}%\")\n",
        "print(f\"Macro F1-Score: {macro_f1*100:.2f}%\")\n",
        "print(f\"Best Training Accuracy: {max(training_results['val_accuracies']):.2f}%\")\n",
        "\n",
        "if CONFIG[\"use_weighted_loss\"]:\n",
        "    print(f\"\\n‚úÖ Weighted Loss Effectiveness:\")\n",
        "    print(f\"- Minority class average performance: {minority_avg_acc:.2f}%\")\n",
        "    print(f\"- Performance gap reduced through weighted loss function\")\n",
        "    if minority_avg_acc > 70:\n",
        "        print(f\"- ‚úÖ Good minority class performance achieved\")\n",
        "    else:\n",
        "        print(f\"- ‚ö†Ô∏è Consider additional techniques for minority classes\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0ea7a02e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ea7a02e",
        "outputId": "c45be662-26f9-4f54-ec21-3ca9c6d80462"
      },
      "outputs": [],
      "source": [
        "# Model Architecture and Training Insights with Class Imbalance Analysis\n",
        "\n",
        "print(\"üèóÔ∏è Model Architecture Summary:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Model Type: Hybrid ResNet-ViT\")\n",
        "print(f\"Backbone: ResNet-50 (Pretrained)\")\n",
        "print(f\"Transformer Heads: {CONFIG['num_heads']}\")\n",
        "print(f\"Transformer Layers: {CONFIG['num_layers']}\")\n",
        "print(f\"Embedding Dimension: {CONFIG['embed_dim']}\")\n",
        "print(f\"Dropout Rate: {CONFIG['dropout']}\")\n",
        "print(f\"Total Parameters: {sum(p.numel() for p in trainer.model.parameters()):,}\")\n",
        "print(\n",
        "    f\"Trainable Parameters: {sum(p.numel() for p in trainer.model.parameters() if p.requires_grad):,}\"\n",
        ")\n",
        "\n",
        "# Training configuration summary\n",
        "print(\"\\n‚öôÔ∏è Training Configuration:\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"Optimizer: AdamW\")\n",
        "print(f\"Learning Rate: {CONFIG['learning_rate']}\")\n",
        "print(f\"Batch Size: {CONFIG['batch_size']}\")\n",
        "print(f\"Planned Epochs: {CONFIG['num_epochs']}\")\n",
        "print(f\"Actual Epochs: {training_results.get('stopped_epoch', CONFIG['num_epochs'])}\")\n",
        "print(\n",
        "    f\"Loss Function: {'Weighted CrossEntropyLoss' if CONFIG['use_weighted_loss'] else 'CrossEntropyLoss'}\"\n",
        ")\n",
        "print(\n",
        "    f\"Class Balancing: {'WeightedRandomSampler' if CONFIG['use_class_balancing'] else 'Standard Sampling'}\"\n",
        ")\n",
        "print(f\"Early Stopping: Enabled (Patience: {CONFIG['early_stopping_patience']}, Delta: {CONFIG['early_stopping_delta']})\")\n",
        "\n",
        "# Data augmentation summary\n",
        "print(\"\\nüîÑ Data Augmentation:\")\n",
        "print(\"=\" * 50)\n",
        "print(\"Training Transforms:\")\n",
        "print(\"- Random Resized Crop to (224, 224)\")\n",
        "print(\"- Random Horizontal Flip (p=0.5)\")\n",
        "print(\"- Random Perspective (distortion=0.3, p=0.5)\")\n",
        "print(\"- Random Rotation (¬±15¬∞, p=0.7)\")\n",
        "print(\"- Color Jitter (brightness, contrast, saturation, p=0.8)\")\n",
        "print(\"- Gaussian Blur (p=0.5)\")\n",
        "print(\"- Coarse Dropout (p=0.2)\")\n",
        "print(\"- ImageNet Normalization\")\n",
        "print(\"\\nValidation Transforms:\")\n",
        "print(\"- Resize to (224, 224)\")\n",
        "print(\"- ImageNet Normalization\")\n",
        "\n",
        "# Class imbalance analysis\n",
        "print(\"\\n‚öñÔ∏è Class Imbalance Analysis:\")\n",
        "print(\"=\" * 50)\n",
        "max_count = class_counts.max().item()\n",
        "min_count = class_counts.min().item()\n",
        "imbalance_ratio = max_count / min_count\n",
        "\n",
        "print(f\"Most frequent class: {max_count} samples\")\n",
        "print(f\"Least frequent class: {min_count} samples\")\n",
        "print(f\"Imbalance ratio: {imbalance_ratio:.2f}x\")\n",
        "\n",
        "if imbalance_ratio > 5:\n",
        "    print(\"‚ö†Ô∏è High imbalance detected!\")\n",
        "    imbalance_level = \"High\"\n",
        "elif imbalance_ratio > 2:\n",
        "    print(\"‚ö†Ô∏è Moderate imbalance detected.\")\n",
        "    imbalance_level = \"Moderate\"\n",
        "else:\n",
        "    print(\"‚úÖ Relatively balanced dataset.\")\n",
        "    imbalance_level = \"Low\"\n",
        "\n",
        "print(\n",
        "    f\"Imbalance handling strategy: {'Weighted Loss' if CONFIG['use_weighted_loss'] else 'None'}\"\n",
        ")\n",
        "\n",
        "# Early stopping analysis\n",
        "print(\"\\nüõë Early Stopping Analysis:\")\n",
        "print(\"=\" * 50)\n",
        "early_stopped = training_results.get(\"early_stopping_triggered\", False)\n",
        "stopped_epoch = training_results.get(\"stopped_epoch\", CONFIG[\"num_epochs\"])\n",
        "planned_epochs = CONFIG[\"num_epochs\"]\n",
        "\n",
        "print(f\"Early Stopping Triggered: {'Yes' if early_stopped else 'No'}\")\n",
        "print(f\"Stopped at Epoch: {stopped_epoch}/{planned_epochs}\")\n",
        "if early_stopped:\n",
        "    epochs_saved = planned_epochs - stopped_epoch\n",
        "    time_per_epoch = np.mean(training_results[\"epoch_times\"])\n",
        "    time_saved = epochs_saved * time_per_epoch / 60\n",
        "    print(f\"Epochs Saved: {epochs_saved}\")\n",
        "    print(f\"Time Saved: ~{time_saved:.1f} minutes\")\n",
        "    print(f\"Efficiency Gain: {(epochs_saved/planned_epochs)*100:.1f}%\")\n",
        "else:\n",
        "    print(f\"Training completed all planned epochs\")\n",
        "\n",
        "print(f\"Best Validation Loss: {training_results.get('best_val_loss', 'N/A'):.6f}\")\n",
        "print(f\"Patience Used: {CONFIG['early_stopping_patience']} epochs\")\n",
        "print(f\"Delta Threshold: {CONFIG['early_stopping_delta']}\")\n",
        "\n",
        "# Training insights and recommendations\n",
        "print(\"\\nüí° Training Insights & Recommendations:\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Analyze training behavior\n",
        "final_train_loss = training_results[\"train_losses\"][-1]\n",
        "final_val_loss = training_results[\"val_losses\"][-1]\n",
        "loss_gap = final_val_loss - final_train_loss\n",
        "best_epoch = (\n",
        "    training_results[\"val_accuracies\"].index(max(training_results[\"val_accuracies\"]))\n",
        "    + 1\n",
        ")\n",
        "\n",
        "print(\"1. Convergence Analysis:\")\n",
        "print(f\"- Final Training Loss: {final_train_loss:.4f}\")\n",
        "print(f\"- Final Validation Loss: {final_val_loss:.4f}\")\n",
        "print(f\"- Loss Gap: {loss_gap:.4f}\")\n",
        "\n",
        "if loss_gap > 0.5:\n",
        "    print(\"‚ö†Ô∏è Large gap suggests potential overfitting\")\n",
        "    print(\n",
        "        \"üí° Consider: Increase dropout, reduce model complexity, or add regularization\"\n",
        "    )\n",
        "elif loss_gap < 0.1:\n",
        "    print(\"‚úÖ Good generalization - minimal overfitting\")\n",
        "else:\n",
        "    print(\"‚úÖ Reasonable generalization gap\")\n",
        "\n",
        "print(\"\\n2. Performance Analysis:\")\n",
        "print(\n",
        "    f\"- Best Accuracy Achieved: {max(training_results['val_accuracies']):.2f}% (Epoch {best_epoch})\"\n",
        ")\n",
        "print(f\"- Final Accuracy: {training_results['val_accuracies'][-1]:.2f}%\")\n",
        "print(f\"- Minority Class Performance: {minority_avg_acc:.2f}%\")\n",
        "print(f\"- Majority Class Performance: {majority_avg_acc:.2f}%\")\n",
        "\n",
        "if early_stopped:\n",
        "    if best_epoch < stopped_epoch - 2:\n",
        "        print(\"‚ö†Ô∏è Best performance was achieved well before early stopping\")\n",
        "        print(\"üí° Consider: Reducing patience or implementing accuracy-based stopping\")\n",
        "    else:\n",
        "        print(\"‚úÖ Early stopping prevented overfitting effectively\")\n",
        "else:\n",
        "    if best_epoch < CONFIG[\"num_epochs\"] - 2:\n",
        "        print(\"‚ö†Ô∏è Best performance was achieved early - possible overfitting\")\n",
        "        print(\"üí° Consider: Early stopping or learning rate scheduling\")\n",
        "    else:\n",
        "        print(\"‚úÖ Model continued improving until the end\")\n",
        "\n",
        "# Compute accuracy trend in last epochs\n",
        "last_epochs = min(5, len(training_results[\"val_accuracies\"]))\n",
        "last_acc = training_results[\"val_accuracies\"][-last_epochs:]\n",
        "acc_trend = np.mean(np.diff(last_acc))\n",
        "\n",
        "print(\"\\n3. Learning Stability:\")\n",
        "if acc_trend > 0.1:\n",
        "    print(\"‚úÖ Model still improving in final epochs\")\n",
        "elif abs(acc_trend) < 0.1:\n",
        "    print(\"‚úÖ Model has converged to stable performance\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Performance declining in final epochs\")\n",
        "    print(\"üí° Early stopping prevented further degradation\" if early_stopped else \"üí° Consider: Early stopping or learning rate decay\")\n",
        "\n",
        "print(\"\\n4. Early Stopping Effectiveness:\")\n",
        "if early_stopped:\n",
        "    counter_history = training_results.get(\"early_stopping_counter_history\", [])\n",
        "    max_counter = max(counter_history) if counter_history else 0\n",
        "    avg_counter = np.mean(counter_history) if counter_history else 0\n",
        "    \n",
        "    print(f\"‚úÖ Early stopping saved {planned_epochs - stopped_epoch} epochs\")\n",
        "    print(f\"üìä Max patience counter reached: {max_counter}/{CONFIG['early_stopping_patience']}\")\n",
        "    print(f\"üìä Average patience counter: {avg_counter:.1f}\")\n",
        "    \n",
        "    if max_counter >= CONFIG['early_stopping_patience']:\n",
        "        print(\"üéØ Patience threshold was appropriately set\")\n",
        "    else:\n",
        "        print(\"üí° Consider: Reducing patience for faster training\")\n",
        "        \n",
        "    # Check if early stopping was too aggressive\n",
        "    post_best_epochs = stopped_epoch - best_epoch if best_epoch < stopped_epoch else 0\n",
        "    if post_best_epochs > CONFIG['early_stopping_patience']:\n",
        "        print(\"‚ö†Ô∏è Early stopping may have been too patient\")\n",
        "        print(\"üí° Consider: Using accuracy-based early stopping or reducing patience\")\n",
        "else:\n",
        "    final_counter = training_results.get(\"early_stopping_counter_history\", [0])[-1]\n",
        "    print(f\"üìä Final patience counter: {final_counter}/{CONFIG['early_stopping_patience']}\")\n",
        "    \n",
        "    if final_counter > CONFIG['early_stopping_patience'] * 0.7:\n",
        "        print(\"üí° Model was close to early stopping - patience was well-tuned\")\n",
        "    else:\n",
        "        print(\"üí° Consider: Reducing patience if training time is a concern\")\n",
        "\n",
        "print(\"\\n5. Class Imbalance Handling Effectiveness:\")\n",
        "if CONFIG[\"use_weighted_loss\"]:\n",
        "    print(\"‚úÖ Weighted loss function used\")\n",
        "    gap = abs(majority_avg_acc - minority_avg_acc)\n",
        "    if gap < 10:\n",
        "        print(f\"‚úÖ Good balance: {gap:.1f}% performance gap between class groups\")\n",
        "    else:\n",
        "        print(f\"‚ö†Ô∏è Still some imbalance: {gap:.1f}% performance gap\")\n",
        "        print(\"üí° Consider: Focal loss, SMOTE, or additional data collection\")\n",
        "\n",
        "print(\"\\n6. Recommendations for Next Steps:\")\n",
        "print(\"üîÑ Experiment with different learning rates (1e-5, 5e-5)\")\n",
        "print(\"üìà Try learning rate scheduling (CosineAnnealingLR, ReduceLROnPlateau)\")\n",
        "print(\"üîß Fine-tune hyperparameters (batch size, dropout, transformer layers)\")\n",
        "\n",
        "# Early stopping specific recommendations\n",
        "if early_stopped:\n",
        "    if stopped_epoch < planned_epochs * 0.3:\n",
        "        print(\"üõë Early stopping triggered very early:\")\n",
        "        print(\"- Increase patience (10-15 epochs)\")\n",
        "        print(\"- Add learning rate warmup\")\n",
        "        print(\"- Consider different delta threshold\")\n",
        "    elif stopped_epoch > planned_epochs * 0.9:\n",
        "        print(\"üõë Early stopping triggered very late:\")\n",
        "        print(\"- Reduce patience (3-5 epochs)\")\n",
        "        print(\"- Consider stricter delta threshold\")\n",
        "    else:\n",
        "        print(\"üõë Early stopping timing was appropriate\")\n",
        "        print(\"- Current patience setting works well\")\n",
        "else:\n",
        "    print(\"üõë For future training with early stopping:\")\n",
        "    print(\"- Current patience might be too high\")\n",
        "    print(\"- Consider reducing to 5-7 epochs\")\n",
        "    print(\"- Monitor validation loss more strictly\")\n",
        "\n",
        "if imbalance_level == \"High\":\n",
        "    print(\"‚öñÔ∏è For high imbalance:\")\n",
        "    print(\"- Try focal loss (gamma=2.0)\")\n",
        "    print(\"- Consider SMOTE or synthetic data generation\")\n",
        "    print(\"- Collect more data for minority classes\")\n",
        "elif minority_avg_acc < majority_avg_acc - 15:\n",
        "    print(\"‚öñÔ∏è For persistent class imbalance:\")\n",
        "    print(\"- Increase class weights for poorly performing classes\")\n",
        "    print(\"- Try class-balanced sampling\")\n",
        "    print(\"- Consider ensemble methods\")\n",
        "\n",
        "print(\"üéØ Consider ensemble methods for better performance\")\n",
        "print(\"üìä Monitor per-class metrics in addition to overall accuracy\")\n",
        "\n",
        "# Enhanced performance summary table with early stopping info\n",
        "performance_summary = pd.DataFrame(\n",
        "    {\n",
        "        \"Class\": classes,\n",
        "        \"Training_Size\": [class_performance[cls][\"count\"] for cls in classes],\n",
        "        \"Accuracy\": [class_performance[cls][\"accuracy\"] for cls in classes],\n",
        "        \"Precision\": [class_performance[cls][\"precision\"] for cls in classes],\n",
        "        \"Recall\": [class_performance[cls][\"recall\"] for cls in classes],\n",
        "        \"F1_Score\": [class_performance[cls][\"f1\"] for cls in classes],\n",
        "        \"Val_Samples\": [class_performance[cls][\"samples_in_val\"] for cls in classes],\n",
        "    }\n",
        ")\n",
        "\n",
        "# Round values and sort by training size\n",
        "performance_summary = performance_summary.round(2).sort_values(\"Training_Size\")\n",
        "\n",
        "print(\"\\nüìä Class Performance Summary Table:\")\n",
        "print(\"=\" * 80)\n",
        "print(performance_summary.to_string(index=False))\n",
        "\n",
        "# Save enhanced training history\n",
        "history_df = pd.DataFrame(\n",
        "    {\n",
        "        \"epoch\": epochs,\n",
        "        \"train_loss\": training_results[\"train_losses\"],\n",
        "        \"val_loss\": training_results[\"val_losses\"],\n",
        "        \"val_accuracy\": training_results[\"val_accuracies\"],\n",
        "        \"epoch_time\": training_results[\"epoch_times\"],\n",
        "        \"early_stopping_counter\": training_results.get(\"early_stopping_counter_history\", [0] * len(epochs)),\n",
        "    }\n",
        ")\n",
        "\n",
        "# Reports directory\n",
        "reports_dir = \"models/classification/reports\"\n",
        "os.makedirs(reports_dir, exist_ok=True)\n",
        "\n",
        "# Add configuration info to CSV\n",
        "config_info = f\"\"\"# Configuration: \n",
        "# use_weighted_loss={CONFIG['use_weighted_loss']}, use_class_balancing={CONFIG['use_class_balancing']}\n",
        "# imbalance_ratio={imbalance_ratio:.2f}, early_stopping_patience={CONFIG['early_stopping_patience']}\n",
        "# early_stopping_delta={CONFIG['early_stopping_delta']}, early_stopping_triggered={early_stopped}\n",
        "# stopped_epoch={stopped_epoch}, best_val_loss={training_results.get('best_val_loss', 'N/A')}\n",
        "\"\"\"\n",
        "\n",
        "history_filename = os.path.join(\n",
        "    reports_dir, f\"training_history_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        ")\n",
        "\n",
        "with open(history_filename, \"w\") as f:\n",
        "    f.write(config_info)\n",
        "    history_df.to_csv(f, index=False)\n",
        "\n",
        "# Save class performance summary\n",
        "perf_filename = os.path.join(\n",
        "    reports_dir, f\"class_performance_{datetime.now().strftime('%Y%m%d_%H%M%S')}.csv\"\n",
        ")\n",
        "performance_summary.to_csv(perf_filename, index=False)\n",
        "\n",
        "# Save early stopping summary\n",
        "if early_stopped:\n",
        "    es_summary = {\n",
        "        \"early_stopping_triggered\": early_stopped,\n",
        "        \"stopped_epoch\": stopped_epoch,\n",
        "        \"planned_epochs\": planned_epochs,\n",
        "        \"epochs_saved\": planned_epochs - stopped_epoch,\n",
        "        \"best_val_loss\": training_results.get('best_val_loss'),\n",
        "        \"patience_used\": CONFIG['early_stopping_patience'],\n",
        "        \"delta_threshold\": CONFIG['early_stopping_delta'],\n",
        "        \"time_saved_minutes\": (planned_epochs - stopped_epoch) * np.mean(training_results[\"epoch_times\"]) / 60,\n",
        "    }\n",
        "    \n",
        "    es_filename = os.path.join(\n",
        "        reports_dir, f\"early_stopping_summary_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json\"\n",
        "    )\n",
        "    import json\n",
        "    with open(es_filename, \"w\") as f:\n",
        "        json.dump(es_summary, f, indent=2)\n",
        "    \n",
        "    print(f\"\\nüõë Early stopping summary saved to: {es_filename}\")\n",
        "\n",
        "print(f\"\\nüíæ Training history saved to: {history_filename}\")\n",
        "print(f\"üìä Class performance saved to: {perf_filename}\")\n",
        "print(f\"üéØ Best model saved to: {CONFIG['result_path']}\")\n",
        "if training_results.get('best_accuracy'):\n",
        "    best_acc_path = CONFIG['result_path'].replace('.pth', '_best_acc.pth')\n",
        "    print(f\"üèÜ Best accuracy model saved to: {best_acc_path}\")\n",
        "\n",
        "print(\"\\nüéâ Training Analysis Complete!\")\n",
        "print(\"=\" * 50)\n",
        "print(f\"üéØ Final Summary:\")\n",
        "print(f\"- Training completed in {stopped_epoch} epochs (planned: {planned_epochs})\")\n",
        "print(f\"- Best validation accuracy: {max(training_results['val_accuracies']):.2f}%\")\n",
        "print(f\"- Early stopping: {'Activated' if early_stopped else 'Not triggered'}\")\n",
        "print(f\"- Total training time: {sum(training_results['epoch_times'])/60:.2f} minutes\")\n",
        "if early_stopped:\n",
        "    time_saved = (planned_epochs - stopped_epoch) * np.mean(training_results[\"epoch_times\"]) / 60\n",
        "    print(f\"- Time saved by early stopping: {time_saved:.1f} minutes\")\n",
        "print(f\"- Class imbalance: {imbalance_level} (ratio: {imbalance_ratio:.2f}x)\")\n",
        "print(f\"- Model saved with best validation loss: {training_results.get('best_val_loss', 'N/A'):.6f}\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
